{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPa9OYMUmNloYGP+Q+pHzGT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaJ9801/TRYONDIFFUSION1.0/blob/main/torch_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What is Pytorch?\n",
        "PyTorch is an open-source machine learning library for Python developed by Facebook's AI Research Lab (FAIR). It is widely used for building deep learning models and conducting research in various fields like computer vision, natural language processing, and reinforcement learning."
      ],
      "metadata": {
        "id": "CZcc1IOA5Cfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Why use PyTorch?\n",
        "**It supports tensor computation**: Tensor is the data structure that is similar to the networks, array. It is an n-dimensional array that contains the data. We can perform arbitrary numeric computation on these arrays using the APIs.\n",
        "\n",
        "**It provides Dynamic Graph Computation**: This feature allows us to define the computational graphs dynamically during runtime. This makes it more flexible than the static computation graphs approach in which where the graph structure is fixed and defined before execution,\n",
        "\n",
        "**It provides the Automatic Differentiation**: The Autograd package automatically computes the gradients that are crucial for training the model using optimization algorithms. Thus, we can perform operations on tensors without manually calculating gradients.\n",
        "\n",
        "**It has Support for Python**: It has native support for the Python programming language. Thus, we can easily integrate with existing Python workflows and libraries. This is the reason why it is used by the machine learning and data science communities.\n",
        "\n",
        "**It has its production environment**: PyTorch has the TorchScript which is the high-performance environment for serializing and executing PyTorch models. You can easily compile PyTorch models into a portable intermediate representation (IR) format. Due to this, we can deploy the model on various platforms and devices without requiring the original Python code."
      ],
      "metadata": {
        "id": "-IKONqrl5-k8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-l2iLqS4Wpi",
        "outputId": "613a5f27-0a8a-4000-e79a-d8e0e9e8177c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# install Pytorch\n",
        "!pip install torch torchaudio torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "tensor1 = torch.tensor([1,2,3]) # tensor from list\n",
        "print(\"Tensor from list:\",tensor1)\n",
        "\n",
        "tensor2 = torch.zeros(2,3) #tensor of zeros\n",
        "print(\"Tensor of zeros:\",tensor2)\n",
        "\n",
        "tensor3 = torch.rand(3,2) #random tensor\n",
        "print(\"Random Tensor:\",tensor3)\n",
        "\n",
        "#Addition\n",
        "result_add = tensor1 + tensor2\n",
        "print(\"Addition of two tensors:\",result_add)\n",
        "\n",
        "#Multiplication\n",
        "result_mul = tensor2 * 5\n",
        "print(\"Multiplication result:\", result_mul)\n",
        "\n",
        "#Matrix multiplication\n",
        "result_matmul = torch.matmul(tensor2, tensor3)\n",
        "print(\"Matrix multiplication result:\", result_matmul)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTwKiFED7oR2",
        "outputId": "b620192e-c295-4284-9851-49c620d005bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor from list: tensor([1, 2, 3])\n",
            "Tensor of zeros: tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Random Tensor: tensor([[0.2435, 0.4188],\n",
            "        [0.3398, 0.1966],\n",
            "        [0.4930, 0.3252]])\n",
            "Addition of two tensors: tensor([[1., 2., 3.],\n",
            "        [1., 2., 3.]])\n",
            "Multiplication result: tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Matrix multiplication result: tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Autograd: Automatic Differentiation in PyTorch\n",
        "Now, we will shift our focus on Autograd which is one of the most important topics in the PyTorch basics. The Autograd Module of PyTorch provides the automatic calculation of the gradients. It means that we do not need to calculate the gradients explicitly. You might be thinking what gradient is. So, the gradient represents the rate of change of functions with respect to parameters. This helps us to identify the difference between the predicted outputs and actual labels.\n",
        "\n",
        "Let us take an example to understand this. Suppose, we create two tensors with names ‘x’ and ‘y’ and perform some computation on them. The result is stored in the variable ‘z.’ Then, we can call the backward() method to calculate the gradient of the z with respect to x and y. This is shown in the below code snippet."
      ],
      "metadata": {
        "id": "Q_Q-bDRfA_Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "z= x**2 + y**3\n",
        "print(\"output tensor z:\", z)\n",
        "\n",
        "z.backward()\n",
        "print(\"Gradient of x:\", x.grad)\n",
        "print(\"Gradient of y:\", y.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktuZYJIF-B2G",
        "outputId": "029e24d8-ccb3-48a1-abf4-8847e57056f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output tensor z: tensor(31., grad_fn=<AddBackward0>)\n",
            "Gradient of x: tensor(4.)\n",
            "Gradient of y: tensor(27.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basics of nn.Module and nn.Parameter\n",
        "The ‘**nn.Module**’ is a base class in PyTorch for all neural network modules. It includes the trainable parameters and defines the forward method for performing forward-pass computations. Thus, it is responsible for parameter management and submodule management, Serialization, and Loading.\n",
        "\n",
        "On the other hand, **nn.Parameter** is the subclass of the torch.Tensor that is responsible for parameter initialization, optimization, and access. The nn.Parameter tensors are defined as attributes within the nn.Module subclass. The nn.Parameter tensors behave like regular tensors but are recognized as model parameters by PyTorch's Autograd system."
      ],
      "metadata": {
        "id": "yfqOttusE4Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Building Neural Network using PyTorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#load Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "#Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.2, random_state=42)\n",
        "\n",
        "#Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#define the neural network architecture\n",
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(SimpleNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size,hidden_size) #Input Layer\n",
        "    self.relu = nn.ReLU() #Activation function\n",
        "    self.fc2 = nn.Linear(hidden_size, output_size) # Output Layer\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "9orYeybWCrSa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After defining the architecture, we have to train the model. In the following code snippet, we set a random seed for reproducibility, and define the input, hidden, and output sizes of the neural network architecture. After this, we instantiate the neural network model, define the **loss function (CrossEntropyLoss) and optimizer (Adam)**, convert the training data to PyTorch tensors, and train the model for a fixed number of epochs.\n",
        "\n",
        "During training, we perform forward pass computations to obtain predicted outputs and calculate the loss between predicted and actual labels. Also, we have to update model parameters using the optimizer."
      ],
      "metadata": {
        "id": "s7SPU-bTN0ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set randoom seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define the input size , hidden size and output size of neural network\n",
        "input_size = X.shape[1]\n",
        "hidden_size = 10\n",
        "output_size = len(iris.target_names)\n",
        "\n",
        "#Instantiate the neural network\n",
        "model = SimpleNN(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "#convert data to PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train)\n",
        "y_train_tensor = torch.LongTensor(y_train)\n",
        "\n",
        "#train the model\n",
        "num_epochs = 100\n",
        "for epochs in range (num_epochs):\n",
        "  # Forward pass\n",
        "  output = model(X_train_tensor)\n",
        "  loss = criterion(output, y_train_tensor)\n",
        "\n",
        "  # Backward pass and optimization\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # Print the loss every 10 epochs\n",
        "  if (epochs+1)%10 == 0:\n",
        "    print(f'Epoch [{epochs+1}/{num_epochs}],loss:{loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41zBDF4GN0Az",
        "outputId": "e519dd36-3586-4e61-c6b2-c2221679c4a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100],loss:0.7783\n",
            "Epoch [20/100],loss:0.5399\n",
            "Epoch [30/100],loss:0.3921\n",
            "Epoch [40/100],loss:0.2934\n",
            "Epoch [50/100],loss:0.2166\n",
            "Epoch [60/100],loss:0.1639\n",
            "Epoch [70/100],loss:0.1284\n",
            "Epoch [80/100],loss:0.1050\n",
            "Epoch [90/100],loss:0.0902\n",
            "Epoch [100/100],loss:0.0800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluating the Trained Model\n",
        "Now, our Model has been trained. We will evaluate the model on the test dataset. For this, we have to convert the test dataset from NumPy Arrays into the PyTorch Sensors using the torch.FloatTensor() and torch.LongTensor(). Then, we pass the test input X_test_tensor through the trained model to obtain the output. At last, these are compared with the actual predicted labels y_test_tensor to calculate the accuracy."
      ],
      "metadata": {
        "id": "ik8frget8n-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "with torch.no_grad():\n",
        "  X_test_tensor = torch.FloatTensor(X_test)\n",
        "  y_test_tensor = torch.LongTensor(y_test)\n",
        "  outputs = model(X_test_tensor)\n",
        "  _, predicted = torch.max(outputs, 1)\n",
        "  accuracy = (predicted == y_test_tensor).sum().item()/ len(y_test_tensor)\n",
        "  print(f'Accuracy on the test set: {accuracy: .2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TELiNOXm8s2M",
        "outputId": "9e030c96-e927-4f5d-d25c-f71078876229"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set:  0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Working with Data in PyTorch\n",
        "The development of Machine Learning involves working with data. Thus, the techniques of efficient data handling are crucial while learning PyTorch. So in this section, we will learn about various data handling techniques like Data Loading and Preprocessing.\n",
        "\n",
        "###Loading Data: Using DataLoader and Dataset\n",
        "DataLoader and Dataset classes in PyTorch are the main components for loading and iterating over datasets. Among these two, the Datasets class acts as the interface for custom datasets. You have to use the ‘len’ and ‘getitem’ methods to create Custom dataset for model building using PyTorch.\n",
        "\n",
        "On the other hand, DataLoader iterates over the dataset and fetches batches of samples. After this, it transfers them to the appropriate device (CPU or GPU) so that the model can process them. This is shown in the below code snippet."
      ],
      "metadata": {
        "id": "1RRjDU9LY9r3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Custom Dataset class\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, data, targets):\n",
        "    self.data = data\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx], self.targets[idx]\n",
        "\n",
        "# Example data\n",
        "data = torch.randn(100, 3, 32, 32) # Example image data\n",
        "targets = torch.randint(0,10, (100,)) #Example target labels\n",
        "\n",
        "# Create custom dataset\n",
        "custom_dataset = CustomDataset(data, targets)\n",
        "\n",
        "# create Dataloader\n",
        "batch_size = 32\n",
        "shuffle = True\n",
        "num_workers = 4\n",
        "data_loader = DataLoader(custom_dataset, batch_size=batch_size,shuffle= shuffle,num_workers= num_workers)\n",
        "\n",
        "# Iterate over batches\n",
        "for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "  print(f'Batch {batch_idx+1}: Inputs shape: {inputs.shape}, Targets shape: {targets.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUxgLIbW9-Mm",
        "outputId": "070e00ae-cf35-4913-e452-3d39c1ec21f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: Inputs shape: torch.Size([32, 3, 32, 32]), Targets shape: torch.Size([32])\n",
            "Batch 2: Inputs shape: torch.Size([32, 3, 32, 32]), Targets shape: torch.Size([32])\n",
            "Batch 3: Inputs shape: torch.Size([32, 3, 32, 32]), Targets shape: torch.Size([32])\n",
            "Batch 4: Inputs shape: torch.Size([4, 3, 32, 32]), Targets shape: torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing Data: Transformations and Normalization\n",
        "Preprocessing of the data means bringing the data into the standard format so that data can be fitted into the model. Here, the two main methods are Transformation and Normalization. The **transformation** techniques include various methods including resizing, cropping, rotating, and flipping images.\n",
        "\n",
        "On the other hand, **Normalization** means to scale the data in such a way that it has zero mean and unit variance. The aim of this method is to stabilize the training process and improve the model’s efficiency. The preprocessing of data is demonstrated through the following code snippet."
      ],
      "metadata": {
        "id": "FR0FfYzrfOsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "#define transformation\n",
        "transform = transforms.Compose([transforms.Resize(256), # resize images to 256x256\n",
        "                                transforms.RandomCrop(224), # randomly crop images to 224x224\n",
        "                                transforms.RandomHorizontalFlip(), # randomly flip images horizontally\n",
        "                                transforms.ToTensor(),  # Convert images to tensors\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                     std=[0.229, 0.224, 0.225]) # Normalize images\n",
        "                                ])\n",
        "#Example of applying transformations to image\n",
        "example_image = transforms.ToPILImage()(torch.randn(3, 256, 256)) # Example image tensor\n",
        "transformed_image = transform(example_image)\n",
        "\n",
        "print(\"Transformed image shape:\", transformed_image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoE6hH-8dam4",
        "outputId": "6082f2f3-9b84-43c2-c308-5a1d3c6bec79"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed image shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Handling Custom Datasets\n",
        "Handling the custom dataset means creating a dataset of a specific structure and format.\n",
        "For this, we have to create a custom dataset class that inherits from the ‘torch.utils.data.Dataset’ class.’ Mainly, the ‘__len__’ and ‘__getitem__’ methods are used to handle the custom dataset.\n",
        "The ‘__len__’ method returns the total number of samples in the dataset and the ‘__getitem__’ method fetches the sample and its corresponding target. This is shown in the following code snippet."
      ],
      "metadata": {
        "id": "ZdBJvq0OkdKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define custom dataset class by subclassing torch.utils.data.Dataset\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, data, targets):\n",
        "    self.data = data\n",
        "    self.targets= targets\n",
        "\n",
        "  def __len__(self):\n",
        "    # Return the total number of samples in the dataset\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Retrive and return a sample and its corresponding target based on the given index\n",
        "    sample = self.data[index]\n",
        "    target = self.targets[index]\n",
        "    return sample, target\n",
        "\n",
        "# Example data and targets\n",
        "data = torch.tensor([[1,2],[3,4],[5,6],[7,8]])\n",
        "targets = torch.tensor([0,1,0,1])\n",
        "\n",
        "# Create instance of the custom dataset\n",
        "custom_dataset = CustomDataset(data, targets)\n",
        "\n",
        "# Create a data loader to iterate over the dataset in batches\n",
        "batch_size = 2\n",
        "data_loader = DataLoader(custom_dataset,\n",
        "                         batch_size= batch_size,\n",
        "                         shuffle= True)\n",
        "\n",
        "# Iterate over the data loader to access dataset in batches\n",
        "for batch_idx, (samples, targets) in enumerate(data_loader):\n",
        "  print(f'Batch {batch_idx}:')\n",
        "  print(\"Samples:\",samples)\n",
        "  print(\"Trgets:\", targets)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbSv09qakNlA",
        "outputId": "c99d3816-502b-4076-8a1b-a52ca433462d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0:\n",
            "Samples: tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "Trgets: tensor([0, 1])\n",
            "Batch 1:\n",
            "Samples: tensor([[7, 8],\n",
            "        [5, 6]])\n",
            "Trgets: tensor([1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7_IOF4XZO-Ro"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
